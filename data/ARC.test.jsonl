{"label": "CompareOrContrast", "text": "Resnik ( 1995 ) reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness ."}
{"label": "Background", "text": "Similar observation for surface word frequency was also observed by ( Bertram et al. , 2000 ; Bradley , 1980 ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ; Taft 1975 ; Taft , 2004 ) where it has been claimed that words having low surface frequency tends to decompose ."}
{"label": "Motivation", "text": "But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) ."}
{"label": "Background", "text": "Previous sentiment-analysis work in different domains has considered inter-document similarity ( Agarwal and Bhattacharyya , 2005 ; Pang and Lee , 2005 ; Goldberg and Zhu , 2006 ) or explicit"}
{"label": "Uses", "text": "However , the method we are currently using in the ATIS domain ( Seneff et al. 1991 ) represents our most promising approach to this problem ."}
{"label": "Background", "text": "Henceforth the collaborative traits of blogs and wikis ( McNeill , 2005 ) emphasize annotation , comment , and strong editing ."}
{"label": "Background", "text": "The ICA system ( Hepple , 2000 ) aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance ."}
{"label": "Background", "text": "To this end , several toolkits for building spoken dialogue systems have been developed ( Barnett and Singh , 1997 ; Sasajima et al. , 1999 ) ."}
{"label": "Background", "text": "Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers ( Collins , 1997 ; Charniak , 1997a ; Charniak , 1997b ; Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 ) ."}
{"label": "Background", "text": "Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes Wiebe and Rapaport ( 1988 ) , Hearst ( 1992 ) , Sack ( 1994 ) , and Wiebe ( 1994 ) ; see Esuli ( 2006 ) for an active bibliography ) ."}
{"label": "Background", "text": "Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based ( Lesk , 1986 ) , ontology-based ( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based ( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional ( Weeds and Weir , 2005 ) ."}
{"label": "CompareOrContrast", "text": "Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in ( Florian et al. , 2004 ) and the coreference resolution system is similar to the one described in ( Luo et al. , 2004 ) ."}
{"label": "CompareOrContrast", "text": "The advantage of tuning similarity to the application of interest has been shown previously by Weeds and Weir ( 2005 ) ."}
{"label": "CompareOrContrast", "text": "Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure ."}
{"label": "Background", "text": "Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers ( Collins , 1997 ; Charniak , 1997a ; Charniak , 1997b ; Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 ) ."}
{"label": "Motivation", "text": "We experiment with four learners commonly employed in language learning : Decision List ( DL ) : We use the DL learner as described in Collins and Singer ( 1999 ) , motivated by its success in the related tasks of word sense disambiguation ( Yarowsky , 1995 ) and NE classification ( Collins and Singer , 1999 ) ."}
{"label": "Background", "text": "A central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 ( Pereira and Riley , 1997 ; Knight and Graehl , 1998 ) ."}
{"label": "Uses", "text": "We use the same set of binary features as in previous work on this dataset ( Pang et al. , 2002 ; Pang and Lee , 2004 ; Zaidan et al. , 2007 ) ."}
{"label": "Uses", "text": "Our classification framework , directly inspired by Blum and Chawla ( 2001 ) , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label ."}
{"label": "Background", "text": "As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) ."}
{"label": "CompareOrContrast", "text": "For instance , Palmer and Hearst ( 1997 ) report that the SATZ system ( decision tree variant ) was trained on a set of about 800 labeled periods , which corresponds to a corpus of about 16,000 words ."}
{"label": "Future", "text": "One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by ( Yamada and Knight , 2001 ) ."}
{"label": "Background", "text": "Later works , such as Atallah et al. ( 2001a ) , Bolshakov ( 2004 ) , Taskiran et al. ( 2006 ) and Topkara et al. ( 2006b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method ."}
{"label": "CompareOrContrast", "text": "A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) ."}
{"label": "CompareOrContrast", "text": "The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers ( Ratnaparkhi , 1999 ; Collins , 1999 ; Charniak , 2000 ; Collins , 2000 ; Bod , 2001 ) ."}
{"label": "Background", "text": "The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines ( Curran and Clark , 2003 ; Clark et al. , 2003 ) ."}
{"label": "Background", "text": "This imbalance foils thresholding strategies , clever as they might be ( Gale & Church , 1991 ; Wu & Xia , 1994 ; Chen , 1996 ) ."}
{"label": "Uses", "text": "Training was done on the Penn Treebank ( Marcus et al. , 1993 ) Wall Street Journal data , sections 02-21 ."}
{"label": "Uses", "text": "We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool ( Giuliano , 2007 ) to measure the relatedness between words in the dataset ."}
{"label": "CompareOrContrast", "text": "For example , our previous work ( Nakov and Ng , 2009 ; Nakov and Ng , 2012 ) experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all bi-texts was English ."}
{"label": "Background", "text": "Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based ( Lesk , 1986 ) , ontology-based ( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based ( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional ( Weeds and Weir , 2005 ) ."}
{"label": "Background", "text": "Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information ( Andrews et al. , 2009 ; Steyvers , 2010 ; Feng and Lapata , 2010b ; Bruni et al. , 2011 ; Silberer and Lapata , 2012 ; Johns and Jones , 2012 ; Bruni et al. , 2012a ; Bruni et al. , 2012b ; Silberer et al. , 2013 ) ."}
{"label": "Background", "text": "Gurevych ( 2005 ) replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German ."}
{"label": "Uses", "text": "One approach to this more general problem , taken by the ` Nitrogen ' generator ( Langkilde and Knight , 1998a ; Langkilde and Knight , 1998b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."}
{"label": "Uses", "text": "where mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model ( Berger et al. , 1996 ) ."}
{"label": "Uses", "text": "13 We also employed sequence-based measures using the ROUGE tool set ( Lin and Hovy 2003 ) , with similar results to those obtained with the word-by-word measures ."}
{"label": "Background", "text": "Second , using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition ( Evermann et al. , 2004 ) ."}
{"label": "Uses", "text": "In this section , we validate the contribution of key tag sets and morphological features -- and combinations thereof -- using a different parser : the Easy-First Parser ( Goldberg and Elhadad 2010 ) ."}
{"label": "CompareOrContrast", "text": "The typical solution to the redundancy problem is to group verbs according to their argument realization patterns ( Levin , 1993 ) , possibly arranged in an inheritance hierarchy ."}
{"label": "Background", "text": "Later , Hobbs ( 1979 , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base ."}
{"label": "Background", "text": "Another technique is automatic discovery of translations from parallel or non-parallel corpora ( Fung and Mckeown , 1997 ) ."}
{"label": "Uses", "text": "ASARES is presented in detail in ( Claveau et al. , 2003 ) ."}
{"label": "Background", "text": "Opposition ( called `` adversative '' or `` contrary-to-expectation '' by Halliday and Hasan 1976 ; cfXXX also Quirk et al. 1972 , p. 672 ) ."}
{"label": "Background", "text": "A number of applications have relied on distributional analysis ( Harris , 1971 ) in order to build classes of semantically related terms ."}
{"label": "CompareOrContrast", "text": "Previous work with MaltParser in Russian , Turkish , and Hindi showed gains with CASE but not with agreement features ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; Nivre 2009 ) ."}
{"label": "CompareOrContrast", "text": "Consider , for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by Pollard and Sag ( 1987 , 215 ) in terms of the setup of Pollard and Sag ( 1994 , ch ."}
{"label": "CompareOrContrast", "text": "Two applications that , like help-desk , deal with question -- answer pairs are : summarization of e-mail threads ( Dalli , Xia , and Wilks 2004 ; Shrestha and McKeown 2004 ) , and answer extraction in FAQs ( Frequently Asked Questions ) ( Berger and Mittal 2000 ;"}
{"label": "Background", "text": "The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , Von Ahn ( 2006 ) ) , computing power , improved computer vision models ( Oliva and Torralba , 2001 ; Lowe , 2004 ; Farhadi et al. , 2009 ; Parikh and Grauman , 2011 ) and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm \u00c2\u00a8 uller et al. , 2005 ; Tettamanti et al. , 2005 ; Aziz-Zadeh et al. , 2006 ) ."}
{"label": "CompareOrContrast", "text": "In addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar ( Blunsom et al. 2009 ) 5 ."}
{"label": "Background", "text": "There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research Group , 2001 ) ."}
{"label": "CompareOrContrast", "text": "Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of Kiefer et al. ( 1999 ) , who report large speed-ups from the elimination of disjunction processing during unification ."}
{"label": "Background", "text": "For the task of unsupervised dependency parsing , Smith and Eisner ( 2006 ) add a constraint of the form `` the average length of dependencies should be X '' to capture the locality of syntax ( at least half of the dependencies are between adjacent words ) , using a scheme they call structural annealing ."}
{"label": "Uses", "text": "The speech and language processing architecture is based on that of the SRI CommandTalk system ( Moore et al. , 1997 ; Stent et a. , 1999 ) ."}
{"label": "CompareOrContrast", "text": "Second , in line with the findings of ( Mehdad et al. , 2010 ) , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) ."}
{"label": "CompareOrContrast", "text": "Therefore , inter-subject correlation is lower than the results obtained by Gurevych ( 2006 ) ."}
{"label": "Background", "text": "There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity ( Dowty , 1979 ; Jackendoff , 1983 ; Pustejovsky , 1991b ; Rappaport Hovav and Levin , 1998 ) ."}
{"label": "Background", "text": "For example , some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes ( Strzalkowski 1994 ) ."}
{"label": "CompareOrContrast", "text": "The resulting training procedure is analogous to the one presented in ( Brown et al. , 1993 ) and ( Tillmann and Ney , 1997 ) ."}
{"label": "Uses", "text": "successfully parses , or until a quitting criterion is reached , such as an upper bound on N. Whereas in the loosely coupled system the parser acts as a filter only on completed candidate solutions ( Zue et al. 1991 ) , the tightly coupled system allows the parser to discard partial theories that have no way of continuing ."}
{"label": "CompareOrContrast", "text": "Zollmann and Venugopal ( 2006 ) substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories ."}
{"label": "Background", "text": "Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; Carter 1987 ; Rich and LuperFoy 1988 ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input ."}
{"label": "Background", "text": "The paradigm is `` write many , read many '' ( Cunningham and Leuf , 2001 ) ."}
{"label": "Uses", "text": "The Praat tool was used ( Boersma and Weenink , 2009 ) ."}
{"label": "Background", "text": "2 The reader is asked to focus on any reasonable size measurement , for example , the maximal horizontal or vertical distance , or some combination of dimensions ( Kamp 1975 ; also Section 8.1 of the present article ) ."}
{"label": "Motivation", "text": "The implementation has been inspired by experience in extracting information from very large corpora ( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging ( Curran and Clark , 2003 ; Clark et al. , 2003 ) ."}
{"label": "Future", "text": "Default parameters were used , although experimentation with different parameter settings is an important direction for future work ( Daelemans and Hoste , 2002 ; Munson et al. , 2005 ) ."}
{"label": "Uses", "text": "Our work is inspired by the latent left-linking model in Chang et al. ( 2013 ) and the ILP formulation from Chang et al. ( 2011 ) ."}
{"label": "Background", "text": "Furthermore , the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) ( Lindberg et al. , 1993 ) , and the availability of software that leverages this knowledge -- MetaMap ( Aronson , 2001 ) for concept identification and SemRep ( Rindflesch and Fiszman , 2003 ) for relation extraction -- provide a foundation for studying the role of semantics in various tasks ."}
{"label": "Background", "text": "The names given to the components vary ; they have been called `` strategic '' and `` tactical '' components ( e.g. , McKeown 1985 ; Thompson 1977 ; Danlos 1987 ) 1 , `` planning '' and `` realization '' ( e.g. , McDonald 1983 ; Hovy 1988a ) , or simply `` what to say '' versus `` how to say it '' ( e.g. , Danlos 1987 ; Reithinger 1990 ) ."}
{"label": "Background", "text": "Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations ( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring ( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) ."}
{"label": "Uses", "text": "We use the TRIPS dialogue parser ( Allen et al. , 2007 ) to parse the utterances ."}
{"label": "Uses", "text": "In order to address these limitations in a practical way , we conducted a small user study where we asked four judges ( graduate students from the Faculty of Information Technology at Monash University ) to assess the responses generated by our system ( Marom and Zukerman 2007a ) ."}
{"label": "Uses", "text": "The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search ) ( Nakano et al. , 1999b ) , which is an integrated parsing and discourse processing method ."}
{"label": "Uses", "text": "We applied our system to the XTAG English grammar ( The XTAG Research Group , 2001 ) 3 , which is a large-scale FB-LTAG grammar for English ."}
{"label": "Background", "text": "After the extraction , pruning techniques ( Snover et al. , 2009 ) can be applied to increase the precision of the extracted paraphrases ."}
{"label": "Background", "text": "In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , Bacchiani et al. , 2004 ; Bellegarda , 2004 ; Gao et al. , 2006 ) , to ranking models for Web search applications ."}
{"label": "Background", "text": "GATE goes beyond earlier systems by using a component-based infrastructure ( Cunningham , 2000 ) which the GUI is built on top of ."}
{"label": "Background", "text": "Since sentences can refer to events described by other sentences , we may need also a quotation operator ; Perlis ( 1985 ) describes how first order logic can be augmented with such an operator ."}
{"label": "Uses", "text": "The system uses a knowledge base implemented in the KM representation language ( Clark and Porter , 1999 ; Dzikovska et al. , 2006 ) to represent the state of the world ."}
{"label": "Future", "text": "A possible future direction would be to compare the query string to retrieved results using a method similar to that of Tsuruoka and Tsujii ( 2003 ) ."}
{"label": "Background", "text": "description-level lexical rules ( DLRs ; Meurers 1995 ) .5 2.2.1 Meta-Level Lexical Rules ."}
{"label": "Background", "text": "All EBMT systems , from the initial proposal by Nagao ( 1984 ) to the recent collection of Carl and Way ( 2003 ) , are premised on the availability of subsentential alignments derived from the input bitext ."}
{"label": "Background", "text": "The necessity of this kind of merging of arguments has been recognized before : Charniak and McDermott ( 1985 ) call it abductive unification/matching , Hobbs ( 1978 , 1979 ) refers to such operations using the terms knitting or petty conversational implicature ."}
{"label": "CompareOrContrast", "text": "In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ; Krieger and Nerbonne 1992 ;"}
{"label": "Motivation", "text": "These keywords are potentially useful features because some of them are subclasses of the ACE SCs shown in the left column of Table 1 , while others appear to be correlated with these ACE SCs .2 ( 6 ) INDUCED CLASS : Since the first-sense heuristic used in the previous feature may not be accurate in capturing the SC of an NP , we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. , Hearst ( 1992 ) ) ."}
{"label": "Background", "text": "Other psycholing-uistic studies that confirm the validity of paragraph units can be found in Black and Bower ( 1979 ) and Haberlandt et al. ( 1980 ) ."}
{"label": "CompareOrContrast", "text": "The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers ( Ratnaparkhi , 1999 ; Collins , 1999 ; Charniak , 2000 ; Collins , 2000 ; Bod , 2001 ) ."}
{"label": "Background", "text": "Nevertheless , the full document text is present in most systems , sometimes as the only feature ( Sugiyama and Okumura , 2007 ) and sometimes in combination with others see for instance ( Chen and Martin , 2007 ; Popescu and Magnini , 2007 ) - ."}
{"label": "Future", "text": "In a similar vain to Skut and Brants ( 1998 ) and Buchholz et al. ( 1999 ) , the method extends an existing flat shallow-parsing method to handle composite structures ."}
{"label": "Background", "text": "As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. , Poesio et al. ( 2004 ) ) or Wikipedia ( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( see Bean and Riloff ( 2004 ) ) ."}
{"label": "Extends", "text": "We built a two-stage baseline system , using the perceptron segmentation model from our previous work ( Zhang and Clark , 2007 ) and the perceptron POS tagging model from Collins ( 2002 ) ."}
{"label": "Future", "text": "Note that although our current system uses MeSH headings assigned by human indexers , manually assigned terms can be replaced with automatic processing if needed ( Aronson et al. 2004 ) ."}
{"label": "Background", "text": "Furthermore , medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding ( McCray et al. , 1988 ) ."}
{"label": "Extends", "text": "Previously ( Gerber and Chai 2010 ) , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests ."}
{"label": "Uses", "text": "To model d ( FWi \u00e2\u0088\u0092 1 , S \u00e2\u0086\u0092 T ) , d ( FWi +1 , S \u00e2\u0086\u0092 T ) , i.e. whether Li , S \u00e2\u0086\u0092 T and Ri , S \u00e2\u0086\u0092 T extend beyond the neighboring function word phrase pairs , we utilize the pairwise dominance model of Setiawan et al. ( 2009 ) ."}
{"label": "Motivation", "text": "For instance , Sells ( 1985 , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's favorite fruit ? ''"}
{"label": "Background", "text": "Semantic Role labeling ( SRL ) was first defined in Gildea and Jurafsky ( 2002 ) ."}
{"label": "Background", "text": "AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML ( Garrett , 2005 ) ."}
{"label": "Background", "text": "The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in Baldwin et al. ( 1995 ) , Gaizauskas and Humphreys ( 1996 ) , and Kameyama ( 1997 ) ."}
{"label": "CompareOrContrast", "text": "The most detailed evaluation of link tokens to date was performed by ( Macklovitch & Hannan , 1996 ) , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."}
{"label": "CompareOrContrast", "text": "Log-linear models have proved successful in a wide variety of applications , and are the inspiration behind one of the best current statistical parsers ( Charniak , 2000 ) ."}
{"label": "Background", "text": "While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure ( Church and Hanks 1990 ) :"}
{"label": "Background", "text": "Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system ( Choueka , 1990 ; J \u00c2\u00a8 appinen and Niemist \u00c2\u00a8 o , 1988 ; Kraaij and Pohlmann , 1996 ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved ."}
{"label": "Background", "text": "For shuffling paraphrases , french alternations are partially described in ( Saint-Dizier , 1999 ) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs ."}
{"label": "Background", "text": "A more recent approach , advocated by Rappaport Hovav and Levin ( 1998 ) , describes a basic set of event templates corresponding to Vendler 's event classes ( Vendler , 1957 ) : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )"}
{"label": "Background", "text": "Watanabe ( 1993 ) combines lexical and dependency mappings to form his generalizations ."}
{"label": "Background", "text": "Thus for instance , ( Copestake and Flickinger , 2000 ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and ( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics ."}
{"label": "Extends", "text": "The reordering models we describe follow our previous work using function word models for translation ( Setiawan et al. , 2007 ; Setiawan et al. , 2009 ) ."}
{"label": "Motivation", "text": "And Collins ( 2000 ) argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in Collins and Duffy ( 2002 ) who use exactly the same set of ( all ) tree fragments as proposed in Bod ( 1992 ) ."}
{"label": "Background", "text": "In our work , we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization ( Goldstein et al. 2000 ; Barzilay , Elhadad , and McKeown 2001 ; Barzilay and McKeown 2005 ) ."}
{"label": "Uses", "text": "criteria and data used in our experiments are based on the work of Talbot et al. ( 2011 ) ."}
{"label": "Uses", "text": "We present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0 ( Hovy et al. , 2006 ) ."}
{"label": "CompareOrContrast", "text": "\u00e2\u0080\u00a2 Only qualitative observations of the responses were reported ( no formal evaluation was performed ) ( Lapalme and Kosseim 2003 ; Roy and Subramaniam 2006 ) ."}
{"label": "Background", "text": "And subderivations headed by A1 with external nonterminals only at the leaves , internal nonterminals elsewhere , have probability 1/a1 ( Goodman 1996 ) ."}
{"label": "Uses", "text": "\u00e2\u0080\u00a2 Support vector machines for mapping histories to parser actions ( Kudo and Matsumoto , 2002 ) ."}
{"label": "Background", "text": "Goodman ( 1996 , 1998 ) developed a polynomial time PCFG-reduction of DOP1 whose size is linear in the size of the training set , thus converting the exponential number of subtrees to a compact grammar ."}
{"label": "Background", "text": "Pustejovsky ( 1995 ) avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify ."}
{"label": "Background", "text": "Hohensee and Bender ( 2012 ) have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor ."}
{"label": "Background", "text": "Such approaches have been tried recently in restricted cases ( McCallum et al. , 2000 ; Eisner , 2001b ; Lafferty et al. , 2001 ) ."}
{"label": "Background", "text": "The relation between discourse and prosodic phrasing has been examined in some detail by Bing ( 1985 ) , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse ."}
{"label": "CompareOrContrast", "text": "By contrast , Turkish ( Oflazer et al. , 2003 ; Atalay et al. , 2003 ) exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) ."}
{"label": "Background", "text": "The candidate examples that lead to the most disagreements among the different learners are considered to have the highest TUV ( Cohn , Atlas , and Ladner 1994 ; Freund et al. 1997 ) ."}
{"label": "Uses", "text": "Subsequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit ( Koehn et al. , 2007 ) ."}
{"label": "Background", "text": "Representative systems are described in Boisen et al. ( 1989 ) , De Mattia and Giachin ( 1989 ) , Niedermair ( 1989 ) , Niemann ( 1990 ) , and Young ( 1989 ) ."}
{"label": "Uses", "text": "Our rules for phonological word formation are adopted , for the most part , from G & G , Grosjean and Gee ( 1987 ) , and the account of monosyllabic destressing in Selkirk ( 1984 ) ."}
{"label": "Background", "text": "As a generalization , Briscoe ( 2001 ) notes that lexicons such as COMLEX tend to demonstrate high precision but low recall ."}
{"label": "Background", "text": "Such systems extract information from some types of syntactic units ( clauses in ( Fillmore and Atkins , 1998 ; Gildea and Jurafsky , 2002 ; Hull and Gomez , 1996 ) ; noun phrases in ( Hull and Gomez , 1996 ; Rosario et al. , 2002 ) ) ."}
{"label": "Background", "text": "Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based ( Lesk , 1986 ) , ontology-based ( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based ( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional ( Weeds and Weir , 2005 ) ."}
{"label": "Background", "text": "Besides WordNet , the RTE literature documents the use of a variety of lexical information sources ( Bentivogli et al. , 2010 ; Dagan et al. , 2009 ) ."}
{"label": "CompareOrContrast", "text": "The question answering system developed by Chu-Carroll et al. ( 2003 ) belongs to the merging category of approaches , where the output of an individual method can be used as input to a different method ( this corresponds to Burke 's cascade sub-category ) ."}
{"label": "Background", "text": "More recently , ( Sebastiani , 2002 ) has performed a good survey of document categorization ; recent works can also be found in ( Joachims , 2002 ) , ( Crammer and Singer , 2003 ) , and ( Lewis et al. , 2004 ) ."}
{"label": "Background", "text": "Discriminant analysis has been employed by researchers in automatic text genre detection ( Biber 1993b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables ."}
{"label": "Extends", "text": "This model has previously been shown to provide excellent performance on multiple tasks , including prediction of association norms , word substitution errors , semantic inferences , and word similarity ( Andrews et al. , 2009 ; Silberer and Lapata , 2012 ) ."}
{"label": "Background", "text": "In other words , existing treatments of gradables in GRE fail to take the `` efficiency of language '' into account ( Barwise and Perry 1983 ; see our Section 2 ) ."}
{"label": "Background", "text": "Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ Galley et al. 2004 ; Chiang et al. 2005 ] ) as well as for"}
{"label": "Uses", "text": "Following Miller et al. , 1999 , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) ."}
{"label": "Background", "text": "In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades and Steedman 1982 ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information ."}
{"label": "Extends", "text": "We have shown elsewhere ( Jensen and Binot 1988 ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment ."}
{"label": "Motivation", "text": "Thus rather than a single training procedure , we can actually partition the examples by predicate , and train a 1For a fixed verb , MI is proportional to Keller and Lapata ( 2003 ) 's conditional probability scores for pseudodisambiguation of ( v , n , n \u00e2\u0080\u00b2 ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."}